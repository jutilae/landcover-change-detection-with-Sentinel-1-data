{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f5a989-b89a-4268-a711-c644edbe76f1",
   "metadata": {},
   "source": [
    "# Forest degradiaton detection using Deep Learning Classifaction in CSC's Puhti supercomputer\n",
    "You can get acces to CSC's services from https://research.csc.fi/\n",
    "\n",
    "Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f575cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2918e65-9ef6-4080-8a88-df8924d31a4c",
   "metadata": {},
   "source": [
    "### Set paths according to your folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835be54d-f136-46a0-9a24-4cf544690629",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/scratch/project_2004990/jutilaee/mtk_kehitys/uusimaa'\n",
    "csv_path = os.path.join(base_folder,'uusimaa_signatures_and_features_max_VH.csv')\n",
    "model_path = os.path.join(base_folder,'uusimaa_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b89b70-2d37-4839-8cea-c9e00c855e13",
   "metadata": {},
   "source": [
    "### Load features and labels of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa1bdbb8-821f-4a63-9a2f-bc35ef1088b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_signatures(sig_csv_path, sig_datatype=np.int32):\n",
    "    \"\"\"\n",
    "    Extracts features and class labels from a signature CSV\n",
    "    Parameters\n",
    "    ----------\n",
    "    sig_csv_path : str\n",
    "        The path to the csv\n",
    "    sig_datatype : dtype, optional\n",
    "        The type of pixel data in the signature CSV. Defaults to np.int32\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features : array_like\n",
    "        a numpy array of the shape (feature_count, sample_count)\n",
    "    class_labels : array_like of int\n",
    "        a 1d numpy array of class labels corresponding to the samples in features.\n",
    "\n",
    "    \"\"\"\n",
    "    data = np.genfromtxt(sig_csv_path, delimiter=\",\", dtype=sig_datatype).T\n",
    "    return (data[1:, :].T, data[0, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa48e982-abe5-4f35-9838-e785b44a2c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31245, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels = load_signatures(csv_path,np.float64)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f7a5e-7b53-4ec9-ab82-201031141fb2",
   "metadata": {},
   "source": [
    "### Set again some paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d2e9fe-ecc9-4737-a927-01f8916d066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set working directory and input/output file names.\n",
    "\n",
    "data_folder = \"/scratch/project_2004990/jutilaee/mtk_kehitys/uusimaa\"\n",
    "\n",
    "results_folder = \"/scratch/project_2004990/jutilaee/mtk_kehitys/uusimaa/deep_classification_results\"\n",
    "\n",
    "inputImage = '/scratch/project_2004990/jutilaee/mtk_kehitys/uusimaa/training_data/UM_max_VH_training.tif'\n",
    "labels_dataset = labels\n",
    "\n",
    "# Outputs of the model\n",
    "# Saved model and its weights\n",
    "fullyConnectedModel = os.path.join(results_folder,'fullyConnectedModel_forestloss.json')\n",
    "fullyConnectedWeights = os.path.join(results_folder,'fullyConnectedWeights_forestloss.h5')\n",
    "# Predicted .tif image\n",
    "fullyConnectedImageCropped = os.path.join(results_folder,'uusimaa_fullyConnected.tif')\n",
    "autokeras =  os.path.join(results_folder,'uusimaa_autokeras.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3f4b7-7266-4de3-a8f3-183f6e2e8519",
   "metadata": {},
   "source": [
    "## Part1: Classification using a user-definded neural network architecture\n",
    "### Source for the three following functions https://github.com/csc-training/geocomputing/blob/master/machineLearning/03_deep/07_deepClassification.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b57d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the fully connected model and save it.\n",
    "# Credits: https://github.com/csc-training/geocomputing/blob/master/machineLearning/03_deep/07_deepClassification.py\n",
    "def trainModel(x_train, y_train):\n",
    "    start_time = time.time()    \n",
    "\n",
    "    # Initializing a sequential model\n",
    "    model = models.Sequential()\n",
    "    # adding the first layer containing 64 perceptrons. 27 is representing the number of bands used for training\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(27,)))\n",
    "    # add the first dropout layer\n",
    "    model.add(layers.Dropout(rate=0.2))\n",
    "    # adding more layers to the model\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dropout(rate=0.2))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    # adding the output layer to the model, note:\n",
    "\t# - the activation is 'softmax', should be used for multi-class classification models\n",
    "\t# - size=3, for 3 classes\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    \n",
    "\t# Compile the model, using:\n",
    "\t# - Adam optimizer, often used, but could be some other optimizer too.\n",
    "\t# -- learning_rate is 0.001\n",
    "\t# - categorical_crossentropy loss function (should be used with multi-class classification)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Use one-hot-encoding to define a class for each pixel\n",
    "    y_train_categorical = to_categorical(y_train)\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train,  y_train_categorical , epochs=2, batch_size=128, verbose=2)\t\n",
    "    \n",
    "     # Save the model to disk\n",
    "    # Serialize the model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(fullyConnectedModel, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # Serialize weights to HDF5\n",
    "    model.save_weights(fullyConnectedWeights)\n",
    "    print('Saved model to disk:  \\nModel: ', fullyConnectedModel, '\\nWeights: ',  fullyConnectedWeights)\n",
    "    print('Model training took: ', round((time.time() - start_time), 0), ' seconds')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data and see the model accuracy\n",
    "def estimateModel(trained_model, x_test, y_test):\n",
    "    \n",
    "    print(y_test)\n",
    "\n",
    "    \n",
    "\t# Encode the test data labels\n",
    "    y_test_categorical = to_categorical(y_test)\n",
    "    \n",
    "    #print(y_test_categorical)\n",
    "\t\n",
    "    # Evaluate the performance of the model by the data, it has never seen\n",
    "\t# verbose=0 avoids printing to output a lot of unclear text (good in Puhti)\n",
    "    test_loss, test_acc = trained_model.evaluate(x_test, y_test_categorical, verbose=0)\n",
    "    print('Test accuracy:', test_acc)\n",
    "    \n",
    "\t# Calculate confusion matrix and classification report as we did with shallow classifier.\n",
    "\t# Use scikit-learn functions for that.\n",
    "\t# First predict for the x_test\n",
    "    test_prediction = trained_model.predict(x_test)\t\n",
    "\t# The model returns a 2D array, with:\n",
    "\t# - each row representing one pixel.\n",
    "\t# - each column representing the probablity of this pixel representing each category\t\n",
    "    print ('Test prediction dataframe shape, original 2D: ', test_prediction.shape) \t\n",
    "\t\n",
    "\t# Find which class was most likely for each pixel and select only that class for the output.\n",
    "\t# Output is 1D array, with the most likely class index given for each pixel.\n",
    "\t# Argmax returns the indices of the maximum values \n",
    "    predicted_classes = np.argmax(test_prediction,axis=1)\n",
    "    print ('Test prediction dataframe shape, after argmax, 1D: ', predicted_classes.shape) \t\n",
    "\n",
    "    print('Confusion matrix: \\n', confusion_matrix(y_test, predicted_classes))\n",
    "    print('Classification report: \\n', classification_report(y_test, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff83fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on whole image and save it as .tif file\n",
    "# Otherwise exactly the same as with shallow classifiers, but:\n",
    "# - Load the model from a file.\n",
    "# - argmax is used for the prediction results.\n",
    "# - Data type is changed to in8, keras returns int64, which GDAL does not support.\n",
    "def predictImage(predictedImagePath, predictImage):\n",
    "    # Load json and create model\n",
    "    json_file = open(fullyConnectedModel, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # Load weights into new model\n",
    "    loaded_model.load_weights(fullyConnectedWeights)\n",
    "    print(\"Loaded model from disk\")\n",
    "\t\n",
    "    # Read the satellite image\n",
    "    with rasterio.open(predictImage, 'r') as image_dataset:\n",
    "        start_time = time.time()    \n",
    "        \n",
    "        #Reshape data to 1D as we did before model training\n",
    "        image_data = image_dataset.read()\n",
    "        image_data2 = np.transpose(image_data, (1, 2, 0))\n",
    "        pixels = image_data2.reshape(-1, 27)\n",
    "        \n",
    "        # Predict for all pixels\n",
    "        prediction = loaded_model.predict(pixels)\n",
    "        print ('Prediction dataframe shape, original 2D: ', prediction.shape) \t\n",
    "\t\t# Find the most likely class for each pixel.\n",
    "        predicted_classes = np.argmax(prediction,axis=1)\n",
    "        print ('Prediction dataframe shape, after argmax, 1D: ', predicted_classes.shape) \t\n",
    "\t\t  \n",
    "        # Reshape back to 2D as in original raster image\n",
    "        prediction2D = np.reshape(predicted_classes, (image_dataset.meta['height'], image_dataset.meta['width']))\n",
    "        print('Prediction shape in 2D: ', prediction2D.shape)\n",
    "\t\t\n",
    "\t\t# Change data type to int8\n",
    "        predicted2D_int8 = np.int8(prediction2D)\n",
    "\t\t\n",
    "\t\t# Save the results as .tif file.\n",
    "\t\t# Copy the coordinate system information, image size and other metadata from the satellite image \n",
    "        outputMeta = image_dataset.meta\n",
    "\t\t# Change the number of bands and data type.\n",
    "        outputMeta.update(count=1, dtype='int8')\n",
    "        # Writing the image on the disk\n",
    "        with rasterio.open(predictedImagePath, 'w', **outputMeta) as dst:\n",
    "            dst.write(predicted2D_int8, 1)\n",
    "        \n",
    "        print('Predicting took: ', round((time.time() - start_time), 0), ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38eda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Read the input datasets with Rasterio\n",
    "    #labels_dataset = rasterio.open(labelsImage)\n",
    "    #image_dataset = rasterio.open(inputImage)  \n",
    "    \n",
    "\t# Prepare data for the model\n",
    "    # input_image, input_labels = prepareData(image_dataset, labels_dataset)\n",
    "\t# Divide the data to test and training datasets\n",
    "    features, labels = load_signatures(csv_path,np.float64)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=63)\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    # Fit and predict the fully connected deep learning model on the data. Outputs a .tif image with the predicted classification.\t\n",
    "    print(\"FullyConnected\")\n",
    "    fullyConnectedModel = trainModel(x_train, y_train)\t\n",
    "    estimateModel(fullyConnectedModel, x_test, y_test)\n",
    "    # Predict image for a small training area first\n",
    "    predictImage(fullyConnectedImageCropped, inputImage)\n",
    "    # Predict image then for the whole uusimaa\n",
    "    fullyConnectedImage = os.path.join(results_folder,'whole_uusimaa_fullyConnected.tif')\n",
    "    predictImage(fullyConnectedImage, '/scratch/project_2004990/jutilaee/mtk_kehitys/uusimaa/UM_max_VH.tif')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c7939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started!\n",
      "(18747, 27)\n",
      "(18747,)\n",
      "FullyConnected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 23:18:00.402848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-23 23:18:02.882247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30976 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "147/147 - 4s - loss: 1.1443 - accuracy: 0.4368 - 4s/epoch - 27ms/step\n",
      "Epoch 2/2\n",
      "147/147 - 0s - loss: 0.8129 - accuracy: 0.5895 - 202ms/epoch - 1ms/step\n",
      "Saved model to disk:  \n",
      "Model:  /scratch/project_2004990/jutilaee/mtk_kehitys/uusimaa/deep_classification_results/fullyConnectedModel_forestloss.json \n",
      "Weights:  /scratch/project_2004990/jutilaee/mtk_kehitys/uusimaa/deep_classification_results/fullyConnectedWeights_forestloss.h5\n",
      "Model training took:  8.0  seconds\n",
      "[3. 2. 2. ... 1. 3. 3.]\n",
      "Test accuracy: 0.6488237977027893\n",
      "391/391 [==============================] - 0s 797us/step\n",
      "Test prediction dataframe shape, original 2D:  (12498, 4)\n",
      "Test prediction dataframe shape, after argmax, 1D:  (12498,)\n",
      "Confusion matrix: \n",
      " [[3101  835   73]\n",
      " [2372 1290   99]\n",
      " [ 665  345 3718]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.51      0.77      0.61      4009\n",
      "         2.0       0.52      0.34      0.41      3761\n",
      "         3.0       0.96      0.79      0.86      4728\n",
      "\n",
      "    accuracy                           0.65     12498\n",
      "   macro avg       0.66      0.63      0.63     12498\n",
      "weighted avg       0.68      0.65      0.65     12498\n",
      "\n",
      "Loaded model from disk\n",
      "36523/36523 [==============================] - 26s 722us/step\n",
      "Prediction dataframe shape, original 2D:  (1168710, 4)\n",
      "Prediction dataframe shape, after argmax, 1D:  (1168710,)\n",
      "Prediction shape in 2D:  (815, 1434)\n",
      "Predicting took:  48.0  seconds\n",
      "Loaded model from disk\n",
      "2700000/2700000 [==============================] - 1993s 738us/step\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ### This part just runs the main method and times it\n",
    "    print(\"Script started!\")\n",
    "    start = time.time()\n",
    "    main()\n",
    "    end = time.time()\n",
    "    print(\"Script completed in \" + str(round((end - start),0)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec27ea8-8a71-4f01-9117-c95ef43a3947",
   "metadata": {},
   "source": [
    "## Part2: Classification using the Autokeras pipeline optimizer \n",
    "\n",
    "Info: https://autokeras.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a20b14b-98c8-4a45-affc-9a67f1cf15e8",
   "metadata": {},
   "source": [
    "Autokeras can be installed on Puhti like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cfef7fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting autokeras\n",
      "  Downloading autokeras-1.0.20-py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.4/162.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras-tuner>=1.1.0\n",
      "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 kB\u001b[0m \u001b[31m229.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib64/python3.9/site-packages (from autokeras) (1.5.0)\n",
      "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib64/python3.9/site-packages (from autokeras) (2.10.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from autokeras) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from keras-tuner>=1.1.0->autokeras) (2.28.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib64/python3.9/site-packages (from keras-tuner>=1.1.0->autokeras) (1.23.3)\n",
      "Collecting kt-legacy\n",
      "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.9/site-packages (from keras-tuner>=1.1.0->autokeras) (7.34.0)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.9/site-packages (from keras-tuner>=1.1.0->autokeras) (2.10.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (2.0.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (2.10.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (50.3.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib64/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (3.7.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib64/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (22.9.24)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib64/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (0.27.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib64/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (1.43.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib64/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (3.19.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (1.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (4.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.8.0->autokeras) (14.0.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging->autokeras) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/site-packages (from pandas->autokeras) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->autokeras) (2022.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (2.12.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/site-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.26.12)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.9/site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.13.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (3.0.31)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.1.6)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.1.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.4.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.9/site-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython->keras-tuner>=1.1.0->autokeras) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (5.0.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib64/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard->keras-tuner>=1.1.0->autokeras) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.1)\n",
      "Installing collected packages: kt-legacy, keras-tuner, autokeras\n",
      "Successfully installed autokeras-1.0.20 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install autokeras --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b21ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb271c6-c8af-41fd-aee7-30c56119ab88",
   "metadata": {},
   "source": [
    "###  Split the training data into a training and a test set \n",
    "The image data can be analysed as stack of arrays where a single pixel represesents an one element of an array. \\\n",
    "Therefore, we can use the Structured Data Classifiers from autokeras to classify each pixel to changed or un-changed areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1807ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec373324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the ScruturedDataClassifier\n",
    "clf = ak.StructuredDataClassifier(overwrite=False, max_trials=50, num_classes=3,seed=14)\n",
    "# Perform a so-called one-hot-encoding where the label of the pixel is expressed as a binary-array. For example the label 1 of a one pixel looks like this [0.0, 1.0, 0.0, 0.0]\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "# Use the autokeras.StructuredDataClassifier.fit() -function to perform the pipeline optimization\n",
    "clf.fit(x_train, y_train_categorical, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fad1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the model using the test data\n",
    "estimateModel(clf, x_test, y_test)\n",
    "print(clf.evaluate(x_test, to_categorical(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse the exported model with the summary() -function\n",
    "model = clf.export_model()\n",
    "model.summary()\n",
    "print(x_train.dtype)\n",
    "\n",
    "# Save the model to the disk\n",
    "try:\n",
    "    model.save(os.path.join(results_folder,\"model_autokeras_2512\"), save_format=\"tf\")\n",
    "except Exception:\n",
    "    model.save(os.path.join(results_folder,\"model_autokeras2512.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42d0f329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 15:24:49.671780: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-24 15:24:52.119553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30976 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# Saved models can be loaded like this:\n",
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model(os.path.join(results_folder,\"model_autokeras_2512\"), custom_objects=ak.CUSTOM_OBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1c990c3-2c42-47f6-b81b-881fc51f42d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 27)]              0         \n",
      "                                                                 \n",
      " multi_category_encoding (Mu  (None, 27)               0         \n",
      " ltiCategoryEncoding)                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 27)               55        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              28672     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 4)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 555,579\n",
      "Trainable params: 555,524\n",
      "Non-trainable params: 55\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aefed753-895d-4671-ac18-cbebc85f5e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3. 2. 2. ... 3. 3. 3.]\n",
      "Test accuracy: 0.8468555212020874\n",
      "196/196 [==============================] - 0s 1ms/step\n",
      "Test prediction dataframe shape, original 2D:  (6249, 4)\n",
      "Test prediction dataframe shape, after argmax, 1D:  (6249,)\n",
      "Confusion matrix: \n",
      " [[1430  516   46]\n",
      " [ 265 1587   52]\n",
      " [  32   46 2275]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.83      0.72      0.77      1992\n",
      "         2.0       0.74      0.83      0.78      1904\n",
      "         3.0       0.96      0.97      0.96      2353\n",
      "\n",
      "    accuracy                           0.85      6249\n",
      "   macro avg       0.84      0.84      0.84      6249\n",
      "weighted avg       0.85      0.85      0.85      6249\n",
      "\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.8073 - accuracy: 0.8469\n",
      "[0.8073314428329468, 0.8468555212020874]\n"
     ]
    }
   ],
   "source": [
    "estimateModel(loaded_model, x_test, y_test)\n",
    "print(loaded_model.evaluate(x_test, to_categorical(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e24402ed-5d2b-4b53-9b84-7bd9114e830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = '/scratch/project_2004990/jutilaee/mtk_kehitys/uusimaa/UM_max_VH.tif'\n",
    "output_file_name =  os.path.join(results_folder,'_whole_uusimaa_autokeras_.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce87421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on whole image and save it as .tif file\n",
    "def predictImage(clf, input_image,output_image_path):\n",
    "    #Set file paths for input and output files\n",
    "    #predictedClassesFile = outputImageBase + modelName + '.tif'\n",
    "    #predictedClassesPath = os.path.join(results_folder, predictedClassesFile)\n",
    "    \n",
    "    # Read the satellite image\n",
    "    with rasterio.open(input_image, 'r') as image_dataset:\n",
    "        start_time = time.time()    \n",
    "        \n",
    "        #Reshape data to 1D as we did before model training\n",
    "        #image_data = image_dataset.read()\n",
    "        image_data = image_dataset.read()\n",
    "        image_data2 = np.transpose(image_data, (1, 2, 0))\n",
    "        pixels = image_data2.reshape(-1, 27)\n",
    "        \n",
    "        #Load the model from the saved file\n",
    "        #modelFilePath = os.path.join(base_folder, ('model_' + modelName + '.sav'))\n",
    "        #trained_model = load(modelFilePath)\n",
    "        \n",
    "        # predict the class for each pixel\n",
    "        prediction = clf.predict(pixels)\n",
    "        prediction = np.argmax(prediction, axis=1)\n",
    "        \n",
    "        # Reshape back to 2D\n",
    "        print('Prediction shape in 1D: ', prediction.shape)\n",
    "        prediction2D = np.reshape(prediction, (image_dataset.meta['height'], image_dataset.meta['width']))\n",
    "        #prediction2D = np.reshape(prediction, ( 705, 1213))\n",
    "        print('Prediction shape in 2D: ', prediction2D.shape)\n",
    "        \n",
    "        # Save the results as .tif file.\n",
    "        # Copy the coorindate system information, image size and other metadata from the satellite image \n",
    "        outputMeta = image_dataset.meta\n",
    "        # Change the number of bands and data type.\n",
    "        #outputMeta.update(count=1, dtype='uint8')\n",
    "        outputMeta.update(count=1, dtype='uint8', height=image_dataset.meta['height'], width=image_dataset.meta['width'])\n",
    "        # Writing the image on the disk\n",
    "        with rasterio.open(output_image_path, 'w', **outputMeta) as dst:\n",
    "            dst.write(prediction2D, 1)\n",
    "        print('Predicting took: ', round((time.time() - start_time), 1), ' seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b3992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 195532/2700000 [=>............................] - ETA: 52:43"
     ]
    }
   ],
   "source": [
    "predictImage(loaded_model,input_image,output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca15278-c1d4-416d-9117-6f1f209b2f83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b9ec0c773c83cfca4a12177b064d8f0487fcbe9388af088ab50832188d00733f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
